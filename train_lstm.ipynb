{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & Convert to Sliding Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 100, 52)\n",
      "(1000, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "states = np.load(\"data/states.npy\")\n",
    "labels = np.load(\"data/labels.npy\")\n",
    "\n",
    "states = states.reshape((-1, 100, 52))\n",
    "labels = labels.reshape((-1, 100, 1))\n",
    "\n",
    "print(states.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Array Shape: (1000, 100, 52)\n",
      "Sliding Windows Array Shape: (95, 1000, 5, 52)\n",
      "Original Labels Shape: (1000, 100, 1)\n",
      "Sliding Windows Labels Shape: (95, 1000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Create sliding window arrays\n",
    "\n",
    "original_array = states\n",
    "original_labels = labels\n",
    "\n",
    "# Define window size\n",
    "window_size = 5\n",
    "\n",
    "# Calculate the number of windows\n",
    "num_windows = original_array.shape[1] - window_size + 1\n",
    "\n",
    "# Create a list to store the windows\n",
    "sliding_windows = []\n",
    "sliding_labels = []\n",
    "\n",
    "# Generate sliding windows\n",
    "for i in range(num_windows-1):\n",
    "    window = original_array[:, i : i + window_size, :]\n",
    "    lab = original_labels[:, i + window_size, :]\n",
    "    sliding_windows.append(window)\n",
    "    sliding_labels.append(lab)\n",
    "\n",
    "# Convert the list of windows to a NumPy array\n",
    "sliding_windows_array = np.array(sliding_windows)\n",
    "sliding_labels = np.array(sliding_labels)\n",
    "\n",
    "print(\"Original Array Shape:\", original_array.shape)\n",
    "print(\"Sliding Windows Array Shape:\", sliding_windows_array.shape)\n",
    "\n",
    "print(\"Original Labels Shape:\", original_labels.shape)\n",
    "print(\"Sliding Windows Labels Shape:\", sliding_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95000, 5, 52)\n",
      "(95000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Collapse into a linear dataset of windows and labels\n",
    "states_windows = sliding_windows_array.reshape((-1, 5, 52))\n",
    "labels_windows = sliding_labels.reshape((-1, 1))\n",
    "\n",
    "print(states_windows.shape)\n",
    "print(labels_windows.shape)\n",
    "\n",
    "np.save(\"data/states_windows.npy\", states_windows)\n",
    "np.save(\"data/labels_windows.npy\", labels_windows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from controller.ctrl import LSTMModel, LSTMDataset\n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_windows = np.load(\"data/states_windows.npy\")\n",
    "labels_windows = np.load(\"data/labels_windows.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device Configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset and Dataloader\n",
    "BATCH_SIZE = 128\n",
    "lstm_dataset = LSTMDataset(states_windows, labels_windows)\n",
    "\n",
    "train_size = int(0.8 * len(lstm_dataset))\n",
    "eval_size = len(lstm_dataset) - train_size\n",
    "\n",
    "\n",
    "train_dataset, eval_dataset = random_split(lstm_dataset, [train_size, eval_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LSTM Model\n",
    "INPUT_DIM = 52\n",
    "HIDDEN_DIM = 100\n",
    "LAYER_DIM = 2\n",
    "OUT_DIM = 1\n",
    "LEARNING_RATE = 1e-3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0\n",
      "Epoch: 1/5\t Iteration: 100\t Loss: 0.13921499252319336\n",
      "Epoch: 1/5\t Iteration: 200\t Loss: 0.11256051063537598\n",
      "Epoch: 1/5\t Iteration: 300\t Loss: 0.1519027054309845\n",
      "Epoch: 1/5\t Iteration: 400\t Loss: 0.09588506817817688\n",
      "Epoch: 1/5\t Iteration: 500\t Loss: 0.0485810711979866\n",
      "Epoch: 2/5\t Iteration: 600\t Loss: 0.03915582597255707\n",
      "Epoch: 2/5\t Iteration: 700\t Loss: 0.04482727497816086\n",
      "Epoch: 2/5\t Iteration: 800\t Loss: 0.0481431670486927\n",
      "Epoch: 2/5\t Iteration: 900\t Loss: 0.032337017357349396\n",
      "Epoch: 2/5\t Iteration: 1000\t Loss: 0.07930101454257965\n",
      "Epoch: 2/5\t Iteration: 1100\t Loss: 0.05403017997741699\n",
      "Epoch: 3/5\t Iteration: 1200\t Loss: 0.03795018419623375\n",
      "Epoch: 3/5\t Iteration: 1300\t Loss: 0.049757592380046844\n",
      "Epoch: 3/5\t Iteration: 1400\t Loss: 0.04945026710629463\n",
      "Epoch: 3/5\t Iteration: 1500\t Loss: 0.03282295539975166\n",
      "Epoch: 3/5\t Iteration: 1600\t Loss: 0.019584709778428078\n",
      "Epoch: 3/5\t Iteration: 1700\t Loss: 0.028952032327651978\n",
      "Epoch: 4/5\t Iteration: 1800\t Loss: 0.01570698991417885\n",
      "Epoch: 4/5\t Iteration: 1900\t Loss: 0.04471722990274429\n",
      "Epoch: 4/5\t Iteration: 2000\t Loss: 0.05545198544859886\n",
      "Epoch: 4/5\t Iteration: 2100\t Loss: 0.09043370932340622\n",
      "Epoch: 4/5\t Iteration: 2200\t Loss: 0.0701252818107605\n",
      "Epoch: 4/5\t Iteration: 2300\t Loss: 0.019138507544994354\n",
      "Epoch: 5/5\t Iteration: 2400\t Loss: 0.037494830787181854\n",
      "Epoch: 5/5\t Iteration: 2500\t Loss: 0.0020792947616428137\n",
      "Epoch: 5/5\t Iteration: 2600\t Loss: 0.020707644522190094\n",
      "Epoch: 5/5\t Iteration: 2700\t Loss: 0.046636007726192474\n",
      "Epoch: 5/5\t Iteration: 2800\t Loss: 0.022849678993225098\n",
      "Epoch: 5/5\t Iteration: 2900\t Loss: 0.006922471337020397\n",
      "Trial 1\n",
      "Epoch: 1/5\t Iteration: 100\t Loss: 0.1731398105621338\n",
      "Epoch: 1/5\t Iteration: 200\t Loss: 0.22659967839717865\n",
      "Epoch: 1/5\t Iteration: 300\t Loss: 0.09445279836654663\n",
      "Epoch: 1/5\t Iteration: 400\t Loss: 0.08649638295173645\n",
      "Epoch: 1/5\t Iteration: 500\t Loss: 0.10309174656867981\n",
      "Epoch: 2/5\t Iteration: 600\t Loss: 0.04055410251021385\n",
      "Epoch: 2/5\t Iteration: 700\t Loss: 0.08902774751186371\n",
      "Epoch: 2/5\t Iteration: 800\t Loss: 0.07740244269371033\n",
      "Epoch: 2/5\t Iteration: 900\t Loss: 0.047836579382419586\n",
      "Epoch: 2/5\t Iteration: 1000\t Loss: 0.04035808518528938\n",
      "Epoch: 2/5\t Iteration: 1100\t Loss: 0.025149540975689888\n",
      "Epoch: 3/5\t Iteration: 1200\t Loss: 0.01587286964058876\n",
      "Epoch: 3/5\t Iteration: 1300\t Loss: 0.027669187635183334\n",
      "Epoch: 3/5\t Iteration: 1400\t Loss: 0.02915855124592781\n",
      "Epoch: 3/5\t Iteration: 1500\t Loss: 0.01256299763917923\n",
      "Epoch: 3/5\t Iteration: 1600\t Loss: 0.014932961203157902\n",
      "Epoch: 3/5\t Iteration: 1700\t Loss: 0.023359104990959167\n",
      "Epoch: 4/5\t Iteration: 1800\t Loss: 0.00830833986401558\n",
      "Epoch: 4/5\t Iteration: 1900\t Loss: 0.04308973252773285\n",
      "Epoch: 4/5\t Iteration: 2000\t Loss: 0.025725360959768295\n",
      "Epoch: 4/5\t Iteration: 2100\t Loss: 0.030509591102600098\n",
      "Epoch: 4/5\t Iteration: 2200\t Loss: 0.02190866693854332\n",
      "Epoch: 4/5\t Iteration: 2300\t Loss: 0.041623055934906006\n",
      "Epoch: 5/5\t Iteration: 2400\t Loss: 0.0233432799577713\n",
      "Epoch: 5/5\t Iteration: 2500\t Loss: 0.013361381366848946\n",
      "Epoch: 5/5\t Iteration: 2600\t Loss: 0.04800867289304733\n",
      "Epoch: 5/5\t Iteration: 2700\t Loss: 0.052713196724653244\n",
      "Epoch: 5/5\t Iteration: 2800\t Loss: 0.012927192263305187\n",
      "Epoch: 5/5\t Iteration: 2900\t Loss: 0.04130743443965912\n",
      "Trial 2\n",
      "Epoch: 1/5\t Iteration: 100\t Loss: 0.19957053661346436\n",
      "Epoch: 1/5\t Iteration: 200\t Loss: 0.12662702798843384\n",
      "Epoch: 1/5\t Iteration: 300\t Loss: 0.10392627865076065\n",
      "Epoch: 1/5\t Iteration: 400\t Loss: 0.11118847131729126\n",
      "Epoch: 1/5\t Iteration: 500\t Loss: 0.09179317951202393\n",
      "Epoch: 2/5\t Iteration: 600\t Loss: 0.09998452663421631\n",
      "Epoch: 2/5\t Iteration: 700\t Loss: 0.06473535299301147\n",
      "Epoch: 2/5\t Iteration: 800\t Loss: 0.06571617722511292\n",
      "Epoch: 2/5\t Iteration: 900\t Loss: 0.07605498284101486\n",
      "Epoch: 2/5\t Iteration: 1000\t Loss: 0.0419083833694458\n",
      "Epoch: 2/5\t Iteration: 1100\t Loss: 0.068971186876297\n",
      "Epoch: 3/5\t Iteration: 1200\t Loss: 0.02507886290550232\n",
      "Epoch: 3/5\t Iteration: 1300\t Loss: 0.024420421570539474\n",
      "Epoch: 3/5\t Iteration: 1400\t Loss: 0.017430104315280914\n",
      "Epoch: 3/5\t Iteration: 1500\t Loss: 0.009541492909193039\n",
      "Epoch: 3/5\t Iteration: 1600\t Loss: 0.058244574815034866\n",
      "Epoch: 3/5\t Iteration: 1700\t Loss: 0.010935207828879356\n",
      "Epoch: 4/5\t Iteration: 1800\t Loss: 0.05295267701148987\n",
      "Epoch: 4/5\t Iteration: 1900\t Loss: 0.028799600899219513\n",
      "Epoch: 4/5\t Iteration: 2000\t Loss: 0.014033995568752289\n",
      "Epoch: 4/5\t Iteration: 2100\t Loss: 0.014282933436334133\n",
      "Epoch: 4/5\t Iteration: 2200\t Loss: 0.04789220169186592\n",
      "Epoch: 4/5\t Iteration: 2300\t Loss: 0.029715077951550484\n",
      "Epoch: 5/5\t Iteration: 2400\t Loss: 0.014352323487401009\n",
      "Epoch: 5/5\t Iteration: 2500\t Loss: 0.01884155534207821\n",
      "Epoch: 5/5\t Iteration: 2600\t Loss: 0.01231471262872219\n",
      "Epoch: 5/5\t Iteration: 2700\t Loss: 0.023883774876594543\n",
      "Epoch: 5/5\t Iteration: 2800\t Loss: 0.051335662603378296\n",
      "Epoch: 5/5\t Iteration: 2900\t Loss: 0.01645905151963234\n",
      "Trial 3\n",
      "Epoch: 1/5\t Iteration: 100\t Loss: 0.1760258972644806\n",
      "Epoch: 1/5\t Iteration: 200\t Loss: 0.14812570810317993\n",
      "Epoch: 1/5\t Iteration: 300\t Loss: 0.0641823261976242\n",
      "Epoch: 1/5\t Iteration: 400\t Loss: 0.10313600301742554\n",
      "Epoch: 1/5\t Iteration: 500\t Loss: 0.05661475658416748\n",
      "Epoch: 2/5\t Iteration: 600\t Loss: 0.08820639550685883\n",
      "Epoch: 2/5\t Iteration: 700\t Loss: 0.07128943502902985\n",
      "Epoch: 2/5\t Iteration: 800\t Loss: 0.03755350410938263\n",
      "Epoch: 2/5\t Iteration: 900\t Loss: 0.064231276512146\n",
      "Epoch: 2/5\t Iteration: 1000\t Loss: 0.08771658688783646\n",
      "Epoch: 2/5\t Iteration: 1100\t Loss: 0.03866417706012726\n",
      "Epoch: 3/5\t Iteration: 1200\t Loss: 0.0209372416138649\n",
      "Epoch: 3/5\t Iteration: 1300\t Loss: 0.040264323353767395\n",
      "Epoch: 3/5\t Iteration: 1400\t Loss: 0.029842957854270935\n",
      "Epoch: 3/5\t Iteration: 1500\t Loss: 0.023911412805318832\n",
      "Epoch: 3/5\t Iteration: 1600\t Loss: 0.07658836245536804\n",
      "Epoch: 3/5\t Iteration: 1700\t Loss: 0.027841748669743538\n",
      "Epoch: 4/5\t Iteration: 1800\t Loss: 0.04607803747057915\n",
      "Epoch: 4/5\t Iteration: 1900\t Loss: 0.03345644846558571\n",
      "Epoch: 4/5\t Iteration: 2000\t Loss: 0.05960874259471893\n",
      "Epoch: 4/5\t Iteration: 2100\t Loss: 0.007481157314032316\n",
      "Epoch: 4/5\t Iteration: 2200\t Loss: 0.0392630398273468\n",
      "Epoch: 4/5\t Iteration: 2300\t Loss: 0.028454743325710297\n",
      "Epoch: 5/5\t Iteration: 2400\t Loss: 0.028245611116290092\n",
      "Epoch: 5/5\t Iteration: 2500\t Loss: 0.021508507430553436\n",
      "Epoch: 5/5\t Iteration: 2600\t Loss: 0.03927864134311676\n",
      "Epoch: 5/5\t Iteration: 2700\t Loss: 0.026316359639167786\n",
      "Epoch: 5/5\t Iteration: 2800\t Loss: 0.03811759874224663\n",
      "Epoch: 5/5\t Iteration: 2900\t Loss: 0.028594784438610077\n",
      "Trial 4\n",
      "Epoch: 1/5\t Iteration: 100\t Loss: 0.16753149032592773\n",
      "Epoch: 1/5\t Iteration: 200\t Loss: 0.10578323900699615\n",
      "Epoch: 1/5\t Iteration: 300\t Loss: 0.09706731140613556\n",
      "Epoch: 1/5\t Iteration: 400\t Loss: 0.08613699674606323\n",
      "Epoch: 1/5\t Iteration: 500\t Loss: 0.062345199286937714\n",
      "Epoch: 2/5\t Iteration: 600\t Loss: 0.06762407720088959\n",
      "Epoch: 2/5\t Iteration: 700\t Loss: 0.04471626505255699\n",
      "Epoch: 2/5\t Iteration: 800\t Loss: 0.06825843453407288\n",
      "Epoch: 2/5\t Iteration: 900\t Loss: 0.028820017352700233\n",
      "Epoch: 2/5\t Iteration: 1000\t Loss: 0.08802454173564911\n",
      "Epoch: 2/5\t Iteration: 1100\t Loss: 0.026224929839372635\n",
      "Epoch: 3/5\t Iteration: 1200\t Loss: 0.020378122106194496\n",
      "Epoch: 3/5\t Iteration: 1300\t Loss: 0.043104492127895355\n",
      "Epoch: 3/5\t Iteration: 1400\t Loss: 0.029430249705910683\n",
      "Epoch: 3/5\t Iteration: 1500\t Loss: 0.03849438205361366\n",
      "Epoch: 3/5\t Iteration: 1600\t Loss: 0.02683352679014206\n",
      "Epoch: 3/5\t Iteration: 1700\t Loss: 0.04033036530017853\n",
      "Epoch: 4/5\t Iteration: 1800\t Loss: 0.05353739112615585\n",
      "Epoch: 4/5\t Iteration: 1900\t Loss: 0.04175121709704399\n",
      "Epoch: 4/5\t Iteration: 2000\t Loss: 0.04703518748283386\n",
      "Epoch: 4/5\t Iteration: 2100\t Loss: 0.011550277471542358\n",
      "Epoch: 4/5\t Iteration: 2200\t Loss: 0.018859896808862686\n",
      "Epoch: 4/5\t Iteration: 2300\t Loss: 0.03448157757520676\n",
      "Epoch: 5/5\t Iteration: 2400\t Loss: 0.014563615433871746\n",
      "Epoch: 5/5\t Iteration: 2500\t Loss: 0.011987568810582161\n",
      "Epoch: 5/5\t Iteration: 2600\t Loss: 0.03157597780227661\n",
      "Epoch: 5/5\t Iteration: 2700\t Loss: 0.062052302062511444\n",
      "Epoch: 5/5\t Iteration: 2800\t Loss: 0.06677365303039551\n",
      "Epoch: 5/5\t Iteration: 2900\t Loss: 0.04284647852182388\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 5\n",
    "results = []\n",
    "for i in range(5):\n",
    "    print(\"Trial\", i)\n",
    "    lstm_model = LSTMModel(INPUT_DIM, HIDDEN_DIM, LAYER_DIM, OUT_DIM).to(device)\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = torch.optim.Adam(lstm_model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    # Loss Function\n",
    "    loss_fn = torch.nn.BCELoss()\n",
    "\n",
    "    iter = 0\n",
    "    iter_res = []\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        for i, (states, labels) in enumerate(train_loader):\n",
    "            states = states.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            preds = lstm_model(states)\n",
    "            loss = loss_fn(preds, labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            iter += 1\n",
    "            iter_res.append(loss.item())\n",
    "            if iter % 100 == 0:\n",
    "                # Calculate Loss\n",
    "                print(f'Epoch: {epoch + 1}/{NUM_EPOCHS}\\t Iteration: {iter}\\t Loss: {loss.item()}')\n",
    "    results.append(iter_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"results/lstm_results.npy\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.75263157894737\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "lstm_model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # progress = tqdm.tqdm(eval_loader, total=len(eval_loader))\n",
    "    \n",
    "    # Iterate through test dataset\n",
    "    for states, labels in eval_loader:\n",
    "        images = states.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = lstm_model(images)\n",
    "        predicted = (outputs > 0.5).float()\n",
    "        # Total number of labels\n",
    "        total += labels.size(0)\n",
    "\n",
    "        # Total correct predictions\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "\n",
    "    # Print Accuracy\n",
    "    print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save models\n",
    "SAVE_PATH = 'Models/controller/lstm_model.pth'\n",
    "torch.save(lstm_model.state_dict(), SAVE_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "airtrees",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
